{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import foolbox, time\n",
    "import math\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB *  of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 5)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CIFAR100 Dataset\n",
    "#Quelle\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar100/load_data, abgerufen 14.Juli 2021\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train / 255.0 - 0.5\n",
    "x_test =  x_test / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Images to get CIFAR100 without CIFAR10\n",
    "truth_array = (y_train==0) | (y_train==1) | (y_train==2) | (y_train==3) | (y_train==4) | (y_train==5)| (y_train==6)| (y_train==7)| (y_train==8)| (y_train==9)\n",
    "truth_array_test = (y_test==0) | (y_test==1) | (y_test==2) | (y_test==3) | (y_test==4) | (y_test==5)| (y_test==6)| (y_test==7)| (y_test==8)| (y_test==9)\n",
    "\n",
    "\n",
    "truth_array = truth_array.flatten()\n",
    "truth_array_test = truth_array_test.flatten()\n",
    "#print(truth_array.shape)\n",
    "\n",
    "x_train_new = x_train[~truth_array]\n",
    "dt = np.dtype(np.uint8)\n",
    "y_train_new=np.array([], dtype=dt)\n",
    "\n",
    "\n",
    "for value in y_train:\n",
    "    if value > 9:\n",
    "        y_train_new = np.append(y_train_new, value)\n",
    "\n",
    "print(x_train_new.shape)\n",
    "print(y_train_new.shape)\n",
    "\n",
    "x_test_new = x_test[~truth_array_test]\n",
    "dt = np.dtype(np.uint8)\n",
    "y_test_new=np.array([], dtype=dt)\n",
    "\n",
    "for value in y_test:\n",
    "    if value > 9:\n",
    "        y_test_new = np.append(y_test_new, value)\n",
    "\n",
    "y_train_new = y_train_new.reshape(y_train_new.shape[0], 1)\n",
    "y_test_new = y_test_new.reshape(y_test_new.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py, abgerufen 14.Juli 2021\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_new[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(y_train_new[i][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://github.com/hiaghosh/Defensive-Distillation/blob/master/models/cifar10/cifar10.py, abgerufen 14.Juli 2021\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and Train the Base Model with CIFAR90 classes\n",
    "#Quelle\n",
    "#Architektur CNN: https://arxiv.org/pdf/1608.04644.pdf\n",
    "#https://www.tensorflow.org/guide/keras/sequential_model, abgerufen 14.Juli 2021\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),  \n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),   \n",
    "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),  \n",
    "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'), \n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Flatten(),  \n",
    "  tf.keras.layers.Dense(256,activation='relu'),\n",
    "  tf.keras.layers.Dropout(rate=0.5),\n",
    "  tf.keras.layers.Dense(256,activation='relu'),\n",
    "  tf.keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Quelle\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint, abgerufen 14.Juli 2021\n",
    "\n",
    "checkpoint_filepath = 'tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "#Quelle\n",
    "#https://www.tensorflow.org/guide/keras/train_and_evaluate, abgerufen 14.Juli 2021\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_new,\n",
    "    y_train_new,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test_new, y_test_new),\n",
    "    callbacks=[model_checkpoint_callback,LearningRateScheduler(lr_step_decay, verbose=1)]\n",
    ")\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model for Transfer Learning\n",
    "!mkdir -p saved_models_cifar\n",
    "model.save('saved_models_cifar/base_model_cifar90_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://www.tensorflow.org/tutorials/images/transfer_learning, abgerufen 14.Juli 2021\n",
    "\n",
    "def display_history(history, title):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curve \n",
    "display_history(history, \"CNN Base Model CIFAR90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict random image\n",
    "y=model.predict(x_test_new)\n",
    "print(np.argmax(y[1000]))\n",
    "plt.imshow(x_test_new[1000], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy\n",
    "loss, acc = model.evaluate(x_test_new, y_test_new, verbose=2)\n",
    "print('Accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(model.predict(x_test_new).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model for Transfer Learning\n",
    "new_model = tf.keras.models.load_model('saved_models_cifar/base_model_cifar90_2')\n",
    "\n",
    "#Freeze the layers on the model\n",
    "new_model.trainable = False\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(x_test_new, y_test_new, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(x_test_new).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#Filter Images to get CIFAR10 without CIFAR90\n",
    "truth_array = (y_train==0) | (y_train==1) | (y_train==2) | (y_train==3) | (y_train==4) | (y_train==5)| (y_train==6)| (y_train==7)| (y_train==8)| (y_train==9)\n",
    "truth_array_test = (y_test==0) | (y_test==1) | (y_test==2) | (y_test==3) | (y_test==4) | (y_test==5)| (y_test==6)| (y_test==7)| (y_test==8)| (y_test==9)\n",
    "\n",
    "\n",
    "truth_array = truth_array.flatten()\n",
    "truth_array_test = truth_array_test.flatten()\n",
    "#print(truth_array.shape)\n",
    "\n",
    "x_train_red = x_train[truth_array]\n",
    "dt = np.dtype(np.uint8)\n",
    "y_train_red=np.array([], dtype=dt)\n",
    "\n",
    "\n",
    "for value in y_train:\n",
    "    if value < 10:\n",
    "        y_train_red = np.append(y_train_red, value)\n",
    "\n",
    "print(x_train_red.shape)\n",
    "print(y_train_red.shape)\n",
    "\n",
    "x_test_red = x_test[truth_array_test]\n",
    "dt = np.dtype(np.uint8)\n",
    "y_test_red=np.array([], dtype=dt)\n",
    "\n",
    "for value in y_test:\n",
    "    if value < 10:\n",
    "        y_test_red = np.append(y_test_red, value)\n",
    "\n",
    "y_train_red = y_train_red.reshape(y_train_red.shape[0], 1)\n",
    "y_test_red = y_test_red.reshape(y_test_red.shape[0], 1)\n",
    "\n",
    "#inputs and targets for kFold training set\n",
    "inputs = x_train_red\n",
    "targets = y_train_red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Add a classifier head</h2>\n",
    "\n",
    "Create a new model by adding a classifier on top of the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://github.com/PacktPublishing/Hands-On-Transfer-Learning-with-TensorFlow-2.0-Video, abgerufen 14.Juli 2021\n",
    "def build_mnist_model(base_model):\n",
    "  model = tf.keras.models.Sequential()\n",
    "  for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "        model.add(layer)\n",
    "        print('Layer ' + layer.name + ' frozen.')\n",
    "  model.add(tf.keras.layers.Dense(256,activation='relu')),\n",
    "  model.add(tf.keras.layers.Dropout(rate=0.5)),\n",
    "  model.add(tf.keras.layers.Dense(256,activation='relu')),\n",
    "  model.add(tf.keras.layers.Dense(100, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://scikit-learn.org/stable/modules/cross_validation.html#k-fold, abgerufen 14.Juli 2021\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    #Create and Train the Model for MNIST 7-9\n",
    "    #Quelle\n",
    "    #Architektur CNN: https://arxiv.org/pdf/1608.04644.pdf\n",
    "    #https://www.tensorflow.org/guide/keras/sequential_model, abgerufen 14.Juli 2021\n",
    "    transfer_model = build_mnist_model(new_model)\n",
    "     \n",
    "    transfer_model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    #model.summary()\n",
    "\n",
    "    #Quelle\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint, abgerufen 14.Juli 2021\n",
    "    \n",
    "    checkpoint_filepath = f'tmp/tl_checkpoint_red{fold_no}'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "    \n",
    "    #Quelle\n",
    "    #https://www.tensorflow.org/guide/keras/train_and_evaluate, abgerufen 14.Juli 2021\n",
    "    #Transfer Learning of the Model with CIFAR10 Dataset\n",
    "    history = transfer_model.fit(\n",
    "        inputs[train], targets[train],\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_data=(inputs[test], targets[test]),\n",
    "        callbacks=[model_checkpoint_callback, LearningRateScheduler(lr_step_decay, verbose=1)]\n",
    "    )\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = transfer_model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(transfer_model.metrics_names)\n",
    "    print(f'Score for fold {fold_no}: {transfer_model.metrics_names[0]} of {scores[0]}; {transfer_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    # Save the entire model\n",
    "    !mkdir -p saved_models_mnist_kfold\n",
    "    transfer_model.save(f'saved_models_cifar_kfold/tl_model_cifar_red_{fold_no}')\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Evaluate all 10 models\n",
    "accuracy = list()\n",
    "for i in range(1,11):\n",
    "    model = tf.keras.models.load_model(f'saved_models_cifar_kfold/tl_model_cifar_red_{i}')\n",
    "    model.load_weights(f'tmp/tl_checkpoint_red{i}')\n",
    "\n",
    "    loss, acc = model.evaluate(x_test_red, y_test_red, verbose=2)\n",
    "    print('Accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    accuracy.append(acc)\n",
    "    print(model.predict(x_test_red).shape)\n",
    "    \n",
    "    df = pd.DataFrame(accuracy, columns=['Scores'])\n",
    "    df.to_excel('tl_accuracy_red.xlsx', sheet_name='kfold', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curve \n",
    "display_history(history, \"CNN Model CIFAR10 after Transfer Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model for fine tuning and attacking\n",
    "fine_tune_model = tf.keras.models.load_model(f'saved_models_cifar_kfold/tl_model_cifar_red_10')\n",
    "fine_tune_model.load_weights(f'tmp/tl_checkpoint_red10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze all Layers in base model\n",
    "fine_tune_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print number of layers of model\n",
    "print('Number of layers in the base model: ', len(fine_tune_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://github.com/PacktPublishing/Hands-On-Transfer-Learning-with-TensorFlow-2.0-Video, abgerufen 14.Juli 2021\n",
    "#fine tune from this layer onwards\n",
    "fine_tune_at = 4\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in fine_tune_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "  print('Layer ' + layer.name + ' frozen.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint_ft'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "#Transfer Learning of the Model with CIFAR10 Dataset\n",
    "history = fine_tune_model.fit(\n",
    "    x_train_red,\n",
    "    y_train_red,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test_red, y_test_red),\n",
    "    callbacks=[model_checkpoint_callback, LearningRateScheduler(lr_step_decay, verbose=1)]\n",
    ")\n",
    "\n",
    "fine_tune_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curve \n",
    "display_history(history, \"CNN Model CIFAR10 Reduced after Fine Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Foolbox Packages\n",
    "#Quelle\n",
    "#https://foolbox.readthedocs.io/en/stable/, abgerufen 14.Juli 2021\n",
    "from foolbox import TensorFlowModel, accuracy, samples, Model, utils, attacks, plot\n",
    "from foolbox.attacks import LinfPGD, LinfDeepFoolAttack\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the attack with foolbox\n",
    "#Quelle\n",
    "#https://foolbox.readthedocs.io/en/stable/, abgerufen 14.Juli 2021\n",
    "preprocessing = dict()\n",
    "bounds = (-0.5, 0.5)\n",
    "fmodel = TensorFlowModel(fine_tune_model, bounds=bounds, preprocessing=preprocessing)\n",
    "fmodel = fmodel.transform_bounds((-0.5, 0.5))\n",
    "\n",
    "attack_labels = tf.convert_to_tensor(y_test_red, dtype='int64')\n",
    "attack_labels = tf.reshape(attack_labels, 1000)\n",
    "attack_images = tf.convert_to_tensor(x_test_red, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://www.kaggle.com/josephvm/generating-adversarial-examples-with-foolbox, abgerufen 14.Juli 2021\n",
    "predictions = fine_tune_model.predict(attack_images)\n",
    "orig_predictions = np.argmax(predictions, axis = 1)\n",
    "print(f\"Clean Accuracy:  {np.mean(orig_predictions == attack_labels) * 100:.2f} %\") # Accuracy of original images\n",
    "already_correct = np.sum(orig_predictions != attack_labels) # keep track of how many were already correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quelle\n",
    "#https://foolbox.jonasrauber.de/guide/examples.html, abgerufen 14.Juli 2021\n",
    "#PGD40 mit 20 Restarts\n",
    "import eagerpy as ep\n",
    "attack_images = ep.astensor(attack_images)\n",
    "attack_labels = ep.astensor(attack_labels)\n",
    "attack = attacks.LinfPGD()\n",
    "epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.15,\n",
    "        0.2,\n",
    "        0.25,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "\n",
    "success_rate = np.zeros(len(epsilons))\n",
    "\n",
    "loop_array = np.array_split(np.arange(attack_images.shape[0]), 10)\n",
    "\n",
    "for i , idx in enumerate(loop_array): \n",
    "    restarts = 20\n",
    "\n",
    "    truth_array = np.zeros(shape=(len(epsilons),len(idx)), dtype=bool)\n",
    "    print('Batch: ', i)\n",
    "    for k in range(restarts):\n",
    "        print('Restart: ', k)\n",
    "        raw, clipped, is_adv = attack(fmodel, attack_images[idx], attack_labels[idx], epsilons=epsilons)\n",
    "        arr = is_adv.numpy()\n",
    "        truth_array = truth_array | arr\n",
    "    \n",
    "    success_rate += np.sum(truth_array, axis=1)\n",
    "#print(attack_images.shape)\n",
    "#print('Success Rate:', success_rate / attack_images.shape[0])\n",
    "    \n",
    "print(\"Attack finished!\")\n",
    "print('Success Rate:', success_rate / attack_images.shape[0])\n",
    "df = pd.DataFrame((success_rate / attack_images.shape[0]), columns=['Success_rate'])\n",
    "df.to_excel('attack_success_rate.xlsx', sheet_name='attack', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Versionsinformationen der Module:')\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "!conda --version\n",
    "!python --version\n",
    "print('Tensorflow: ' + tf.__version__)\n",
    "print('Tensorflow Datasets: ' + tfds.__version__)\n",
    "print('Scikit Learn: ' + sklearn.__version__)\n",
    "print('Eagerpy: ' + ep.__version__)\n",
    "print('Numpy: ' + np.__version__)\n",
    "print('Matplotlib: ' + matplotlib.__version__)\n",
    "print('Foolbox: ' + foolbox.__version__)\n",
    "print('Pandas: ' + pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "tf-gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
